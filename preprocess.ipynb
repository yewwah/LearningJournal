{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f6ccb5dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import imgaug\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd33d51c",
   "metadata": {},
   "source": [
    "# Image Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8cca6b08",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import imgaug as ia\n",
    "import imgaug.augmenters as iaa\n",
    "import random\n",
    "import PIL \n",
    "\n",
    "random.seed(10)\n",
    "ia.seed(10)\n",
    "\n",
    "RANDOM = random.random()\n",
    "\n",
    "def dup_img(fname):\n",
    "    arr = np.asarray(PIL.Image.open(fname)).reshape((1, 1500, 2000, 3))\n",
    "    arr = np.repeat(arr, repeats=10, axis=0)\n",
    "    return arr\n",
    "\n",
    "def augment_img(images):\n",
    "# Example batch of images.\n",
    "# The array has shape (32, 64, 64, 3) and dtype uint8.\n",
    "\n",
    "\n",
    "    seq = iaa.Sequential([\n",
    "        iaa.Fliplr(0.5), # horizontal flips\n",
    "        iaa.Crop(percent=(0, 0.1)), # random crops\n",
    "        # Small gaussian blur with random sigma between 0 and 0.5.\n",
    "        # But we only blur about 50% of all images.\n",
    "        iaa.Sometimes(\n",
    "            0.5,\n",
    "            iaa.GaussianBlur(sigma=(0, 0.5))\n",
    "        ),\n",
    "        # Strengthen or weaken the contrast in each image.\n",
    "        iaa.LinearContrast((0.75, 1.5)),\n",
    "        # Add gaussian noise.\n",
    "        # For 50% of all images, we sample the noise once per pixel.\n",
    "        # For the other 50% of all images, we sample the noise per pixel AND\n",
    "        # channel. This can change the color (not only brightness) of the\n",
    "        # pixels.\n",
    "        iaa.AdditiveGaussianNoise(loc=0, scale=(0.0, 0.05*255), per_channel=0.5),\n",
    "        # Make some images brighter and some darker.\n",
    "        # In 20% of all cases, we sample the multiplier once per channel,\n",
    "        # which can end up changing the color of the images.\n",
    "        iaa.Multiply((0.8, 1.2), per_channel=0.2),\n",
    "        # Apply affine transformations to each image.\n",
    "        # Scale/zoom them, translate/move them, rotate them and shear them.\n",
    "\n",
    "        # Randomly apply affine transformations\n",
    "\n",
    "    #     iaa.Affine(\n",
    "    #         scale={\"x\": (0.8, 1.2 * RANDOM), \"y\": (0.8, 1.2* RANDOM)},\n",
    "    #         translate_percent={\"x\": (-0.2, 0.2* RANDOM), \"y\": (-0.2, 0.2* RANDOM)},\n",
    "    #         rotate=(-25* RANDOM, 25* RANDOM),\n",
    "    #         shear=(-8* RANDOM, 8* RANDOM)\n",
    "    #     )\n",
    "    ], random_order=True) # apply augmenters in random order\n",
    "\n",
    "    images_aug = seq(images=images)\n",
    "    \n",
    "    return images_aug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "405a5afd",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = augment_img(dup_img('test.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "af8e4ec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def grayscale_imges(rgb_img_arr):\n",
    "    gray_images = []\n",
    "    for rgb_img in rgb_img_arr:\n",
    "        gray_img = PIL.Image.fromarray(rgb_img).convert('L')\n",
    "        gray_images.append(np.array(gray_img))\n",
    "    return np.array(gray_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ff4645c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 1500, 2000, 3)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "86262ea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "gray_img = grayscale_imges(res)\n",
    "import pickle\n",
    "\n",
    "pickle.dump(gray_img, open('gray_img.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "501f55b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "finalized_mat = gray_img.reshape((gray_img.shape[0], gray_img.shape[1] * gray_img.shape[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "53da6e09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 3000000)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finalized_mat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d870cd56",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "303aa06e",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "n_components=784 must be between 0 and min(n_samples, n_features)=10 with svd_solver='full'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[74], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m pca \u001b[38;5;241m=\u001b[39m PCA(n_components\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m28\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m28\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m \u001b[43mpca\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfinalized_mat\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/sklearn/decomposition/_pca.py:435\u001b[0m, in \u001b[0;36mPCA.fit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    417\u001b[0m \u001b[38;5;124;03m\"\"\"Fit the model with X.\u001b[39;00m\n\u001b[1;32m    418\u001b[0m \n\u001b[1;32m    419\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    431\u001b[0m \u001b[38;5;124;03m    Returns the instance itself.\u001b[39;00m\n\u001b[1;32m    432\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    433\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m--> 435\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    436\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/sklearn/decomposition/_pca.py:512\u001b[0m, in \u001b[0;36mPCA._fit\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    510\u001b[0m \u001b[38;5;66;03m# Call different fits for either full or truncated SVD\u001b[39;00m\n\u001b[1;32m    511\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit_svd_solver \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfull\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 512\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_full\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_components\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    513\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit_svd_solver \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marpack\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrandomized\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[1;32m    514\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit_truncated(X, n_components, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit_svd_solver)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/sklearn/decomposition/_pca.py:526\u001b[0m, in \u001b[0;36mPCA._fit_full\u001b[0;34m(self, X, n_components)\u001b[0m\n\u001b[1;32m    522\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    523\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn_components=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmle\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m is only supported if n_samples >= n_features\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    524\u001b[0m         )\n\u001b[1;32m    525\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;241m0\u001b[39m \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m n_components \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmin\u001b[39m(n_samples, n_features):\n\u001b[0;32m--> 526\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    527\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn_components=\u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m must be between 0 and \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    528\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmin(n_samples, n_features)=\u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m with \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    529\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msvd_solver=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfull\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (n_components, \u001b[38;5;28mmin\u001b[39m(n_samples, n_features))\n\u001b[1;32m    530\u001b[0m     )\n\u001b[1;32m    532\u001b[0m \u001b[38;5;66;03m# Center data\u001b[39;00m\n\u001b[1;32m    533\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmean_ \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmean(X, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: n_components=784 must be between 0 and min(n_samples, n_features)=10 with svd_solver='full'"
     ]
    }
   ],
   "source": [
    "pca = PCA(n_components=28*28)\n",
    "pca.fit(finalized_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba58a2ef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
